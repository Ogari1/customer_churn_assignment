{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4da5d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and explore the dataset: Analyze the distribution of features, check for missing values, and visualize relationships between features and the target variable (churn).\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('Telco-Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce68d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the data: Handle missing values, convert categorical variables to numeric, and normalize/standardize the features if necessary\n",
    "data['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')\n",
    "data['TotalCharges'].fillna(data['TotalCharges'].mean(), inplace=True)\n",
    "\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "categorical_columns = categorical_columns[categorical_columns != 'customerID']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for column in categorical_columns:\n",
    "    data[column] = label_encoder.fit_transform(data[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a94ba324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset: Divide the dataset into training and testing sets.\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = data.drop(['customerID', 'Churn'], axis=1)\n",
    "y = data['Churn']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "test_size = 0.3\n",
    "random_state = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efe2efb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d307e3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train classification models: Train various classification models (e.g., logistic regression, KNN, SVM, decision tree, random forest, etc.) on the training dataset.\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_preds = logreg.predict(X_test)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_preds = rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f3bdf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Accuracy: 0.8106956933270232, Precision: 0.68125, Recall: 0.5696864111498258, F1: 0.6204933586337761\n",
      "Random Forest - Accuracy: 0.7998106956933271, Precision: 0.6882793017456359, Recall: 0.4808362369337979, F1: 0.5661538461538461\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "logreg_accuracy = accuracy_score(y_test, logreg_preds)\n",
    "logreg_precision = precision_score(y_test, logreg_preds)\n",
    "logreg_recall = recall_score(y_test, logreg_preds)\n",
    "logreg_f1 = f1_score(y_test, logreg_preds)\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, rf_preds)\n",
    "rf_precision = precision_score(y_test, rf_preds)\n",
    "rf_recall = recall_score(y_test, rf_preds)\n",
    "rf_f1 = f1_score(y_test, rf_preds)\n",
    "\n",
    "print(f\"Logistic Regression - Accuracy: {logreg_accuracy}, Precision: {logreg_precision}, Recall: {logreg_recall}, F1: {logreg_f1}\")\n",
    "print(f\"Random Forest - Accuracy: {rf_accuracy}, Precision: {rf_precision}, Recall: {rf_recall}, F1: {rf_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "044e0a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "param_grid = {'n_estimators': [10, 50, 100], 'max_depth': [None, 10, 20]}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5856a185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Random Forest Performance:\n",
      "Accuracy: 0.7988641741599621\n",
      "Precision: 0.6651884700665188\n",
      "Recall: 0.5226480836236934\n",
      "F1: 0.5853658536585366\n"
     ]
    }
   ],
   "source": [
    "# Feature selection using Recursive Feature Elimination (RFE)\n",
    "rfe = RFE(estimator=RandomForestClassifier(**best_params), n_features_to_select=10)\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "# Train an optimized Random Forest classifier on the selected features\n",
    "rf_optimized = RandomForestClassifier(**best_params)\n",
    "rf_optimized.fit(X_train_rfe, y_train)\n",
    "rf_optimized_preds = rf_optimized.predict(X_test_rfe)\n",
    "\n",
    "# Evaluate the performance of the optimized Random Forest classifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "rf_optimized_accuracy = accuracy_score(y_test, rf_optimized_preds)\n",
    "rf_optimized_precision = precision_score(y_test, rf_optimized_preds)\n",
    "rf_optimized_recall = recall_score(y_test, rf_optimized_preds)\n",
    "rf_optimized_f1 = f1_score(y_test, rf_optimized_preds)\n",
    "\n",
    "print(f\"Optimized Random Forest Performance:\\nAccuracy: {rf_optimized_accuracy}\\nPrecision: {rf_optimized_precision}\\nRecall: {rf_optimized_recall}\\nF1: {rf_optimized_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8203b3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Important Features:\n",
      "TotalCharges        0.199083\n",
      "MonthlyCharges      0.195954\n",
      "tenure              0.172331\n",
      "Contract            0.156924\n",
      "OnlineSecurity      0.079895\n",
      "TechSupport         0.052843\n",
      "PaymentMethod       0.047449\n",
      "InternetService     0.040363\n",
      "OnlineBackup        0.029561\n",
      "PaperlessBilling    0.025597\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Identifying important features\n",
    "important_features = pd.Series(rf_optimized.feature_importances_, index=X.columns[rfe.support_])\n",
    "important_features = important_features.sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nImportant Features:\")\n",
    "print(important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae757654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "According to the evaluation metrics, the Optimized Random Forest model emerges as the most proficient performer.\n",
      "The primary factors influencing customer churn prediction, as per the analysis, include:\n",
      "TotalCharges      0.199083\n",
      "MonthlyCharges    0.195954\n",
      "tenure            0.172331\n",
      "Contract          0.156924\n",
      "OnlineSecurity    0.079895\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Conclusion\n",
    "print(\"\\nAccording to the evaluation metrics, the Optimized Random Forest model emerges as the most proficient performer.\")\n",
    "print(\"The primary factors influencing customer churn prediction, as per the analysis, include:\")\n",
    "print(important_features.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c7027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
